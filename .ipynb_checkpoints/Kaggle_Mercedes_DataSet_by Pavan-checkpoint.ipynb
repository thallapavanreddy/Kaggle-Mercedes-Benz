{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercedes-Benz DataSet\n",
    "\n",
    "## Problem Statment: Time Take to testing vehicle\n",
    "### Type of Problem: Supervised Classification - Regression Problem\n",
    "#### Evalution By R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1600)\n",
    "pd.set_option('display.max_rows', 1600)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Mercedes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2485c23f2c8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['y'], df['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['y']<150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colum names, Missing values count, Missing values percentage in DataFrame\n",
    "missing_val_df = pd.DataFrame({\n",
    "    'name': df.columns,\n",
    "    'mcount': df.isna().sum(),\n",
    "    'mpercentage': df.isnull().sum()/df.shape[0]*100\n",
    "})\n",
    "\n",
    "#missing_val_df.to_csv(\"missing_values.csv\", index=False)\n",
    "#missing_val_df.sort_values(by='mpercentage', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4194, 376)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "uniqeCol = []\n",
    "for col in X.columns:\n",
    "    if X[col].nunique() == 1:\n",
    "        uniqeCol.append(col)\n",
    "        X.drop(columns=col, inplace=True)\n",
    "print(len(uniqeCol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4194, 363)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4194 entries, 0 to 4208\n",
      "Columns: 363 entries, X0 to X385\n",
      "dtypes: int64(355), object(8)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3355 entries, 2745 to 863\n",
      "Columns: 363 entries, X0 to X385\n",
      "dtypes: int64(355), object(8)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "        return self.label_encoder.transform(new_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Le = LabelEncoderExt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == 'object':\n",
    "        Le.fit(X_train[col])\n",
    "        X_train[col] = Le.transform(X_train[col])\n",
    "        X_test[col] = Le.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "pca = PCA()\n",
    "X_train_pca_df = pd.DataFrame(pca.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca.explained_variance_\n",
    "#pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explained veriance ratio')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Explained veriance ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = pd.DataFrame(pca1.fit_transform(X_train), columns=list(range(0,45)))\n",
    "X_test_pca_df =  pd.DataFrame(pca1.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.544289</td>\n",
       "      <td>-0.824992</td>\n",
       "      <td>2.843841</td>\n",
       "      <td>-2.544883</td>\n",
       "      <td>1.313584</td>\n",
       "      <td>-4.510989</td>\n",
       "      <td>1.497924</td>\n",
       "      <td>-1.848113</td>\n",
       "      <td>2.373872</td>\n",
       "      <td>-0.227971</td>\n",
       "      <td>-1.036275</td>\n",
       "      <td>-0.539821</td>\n",
       "      <td>-0.364789</td>\n",
       "      <td>-0.873245</td>\n",
       "      <td>1.028270</td>\n",
       "      <td>0.284276</td>\n",
       "      <td>0.087572</td>\n",
       "      <td>0.058755</td>\n",
       "      <td>0.663960</td>\n",
       "      <td>-1.168575</td>\n",
       "      <td>-0.508609</td>\n",
       "      <td>0.590425</td>\n",
       "      <td>-0.746908</td>\n",
       "      <td>-0.419889</td>\n",
       "      <td>0.270636</td>\n",
       "      <td>0.157029</td>\n",
       "      <td>-0.098002</td>\n",
       "      <td>0.130397</td>\n",
       "      <td>0.328758</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>0.265257</td>\n",
       "      <td>0.549017</td>\n",
       "      <td>-0.145111</td>\n",
       "      <td>-0.081533</td>\n",
       "      <td>0.217230</td>\n",
       "      <td>-0.029116</td>\n",
       "      <td>-0.072583</td>\n",
       "      <td>-0.152087</td>\n",
       "      <td>-0.228441</td>\n",
       "      <td>-0.159620</td>\n",
       "      <td>-0.102335</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>-0.020124</td>\n",
       "      <td>-0.176160</td>\n",
       "      <td>0.182580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-9.959137</td>\n",
       "      <td>2.312521</td>\n",
       "      <td>-5.690243</td>\n",
       "      <td>16.131003</td>\n",
       "      <td>-4.432750</td>\n",
       "      <td>-2.355228</td>\n",
       "      <td>-0.752267</td>\n",
       "      <td>-2.927850</td>\n",
       "      <td>-0.955590</td>\n",
       "      <td>0.079541</td>\n",
       "      <td>-0.124049</td>\n",
       "      <td>0.271745</td>\n",
       "      <td>-0.429909</td>\n",
       "      <td>-0.377660</td>\n",
       "      <td>0.436714</td>\n",
       "      <td>0.157337</td>\n",
       "      <td>-0.939837</td>\n",
       "      <td>0.660518</td>\n",
       "      <td>0.523079</td>\n",
       "      <td>-0.391293</td>\n",
       "      <td>0.715742</td>\n",
       "      <td>-0.990164</td>\n",
       "      <td>0.508792</td>\n",
       "      <td>-0.129086</td>\n",
       "      <td>0.261061</td>\n",
       "      <td>-0.515424</td>\n",
       "      <td>-0.066966</td>\n",
       "      <td>-0.263788</td>\n",
       "      <td>-0.049874</td>\n",
       "      <td>-0.261616</td>\n",
       "      <td>0.103626</td>\n",
       "      <td>-0.282623</td>\n",
       "      <td>-0.308384</td>\n",
       "      <td>-0.085651</td>\n",
       "      <td>-0.398509</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.362366</td>\n",
       "      <td>-0.057959</td>\n",
       "      <td>-0.335482</td>\n",
       "      <td>-0.068959</td>\n",
       "      <td>-0.203547</td>\n",
       "      <td>0.167375</td>\n",
       "      <td>-0.059329</td>\n",
       "      <td>-0.043762</td>\n",
       "      <td>0.087622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.638594</td>\n",
       "      <td>-1.888735</td>\n",
       "      <td>6.522407</td>\n",
       "      <td>-14.471979</td>\n",
       "      <td>-7.173325</td>\n",
       "      <td>-2.281573</td>\n",
       "      <td>0.788575</td>\n",
       "      <td>-1.923893</td>\n",
       "      <td>1.651099</td>\n",
       "      <td>-0.561468</td>\n",
       "      <td>-0.534815</td>\n",
       "      <td>0.374968</td>\n",
       "      <td>-1.352893</td>\n",
       "      <td>0.309197</td>\n",
       "      <td>-0.471445</td>\n",
       "      <td>0.084420</td>\n",
       "      <td>-0.212422</td>\n",
       "      <td>-0.024082</td>\n",
       "      <td>-0.304529</td>\n",
       "      <td>0.294787</td>\n",
       "      <td>1.086411</td>\n",
       "      <td>-0.627664</td>\n",
       "      <td>0.396498</td>\n",
       "      <td>0.138865</td>\n",
       "      <td>-0.196387</td>\n",
       "      <td>-0.535898</td>\n",
       "      <td>0.735128</td>\n",
       "      <td>0.303894</td>\n",
       "      <td>-0.492485</td>\n",
       "      <td>-0.880517</td>\n",
       "      <td>0.149027</td>\n",
       "      <td>-0.199209</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.216160</td>\n",
       "      <td>-0.168315</td>\n",
       "      <td>-0.335381</td>\n",
       "      <td>-0.156473</td>\n",
       "      <td>0.382928</td>\n",
       "      <td>0.102843</td>\n",
       "      <td>-0.201060</td>\n",
       "      <td>-0.040405</td>\n",
       "      <td>0.226012</td>\n",
       "      <td>-0.006598</td>\n",
       "      <td>0.147990</td>\n",
       "      <td>-0.390312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28.545711</td>\n",
       "      <td>14.048909</td>\n",
       "      <td>-5.890521</td>\n",
       "      <td>8.691848</td>\n",
       "      <td>-2.105240</td>\n",
       "      <td>-2.068995</td>\n",
       "      <td>1.128292</td>\n",
       "      <td>-0.324627</td>\n",
       "      <td>-0.761757</td>\n",
       "      <td>-0.789634</td>\n",
       "      <td>1.633669</td>\n",
       "      <td>-0.576225</td>\n",
       "      <td>1.355751</td>\n",
       "      <td>-0.549355</td>\n",
       "      <td>1.015349</td>\n",
       "      <td>2.146519</td>\n",
       "      <td>-0.432140</td>\n",
       "      <td>-0.589044</td>\n",
       "      <td>-0.127133</td>\n",
       "      <td>0.449501</td>\n",
       "      <td>0.197901</td>\n",
       "      <td>-0.624637</td>\n",
       "      <td>-0.059979</td>\n",
       "      <td>0.319716</td>\n",
       "      <td>0.766709</td>\n",
       "      <td>-0.512455</td>\n",
       "      <td>0.044984</td>\n",
       "      <td>0.236501</td>\n",
       "      <td>-0.246336</td>\n",
       "      <td>0.225709</td>\n",
       "      <td>-0.063760</td>\n",
       "      <td>0.491743</td>\n",
       "      <td>0.171583</td>\n",
       "      <td>-0.360778</td>\n",
       "      <td>0.471259</td>\n",
       "      <td>-0.039643</td>\n",
       "      <td>-0.038446</td>\n",
       "      <td>0.086507</td>\n",
       "      <td>0.462486</td>\n",
       "      <td>0.176038</td>\n",
       "      <td>0.263410</td>\n",
       "      <td>-0.091008</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.395739</td>\n",
       "      <td>-0.456148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-2.263481</td>\n",
       "      <td>-8.139869</td>\n",
       "      <td>11.287388</td>\n",
       "      <td>4.394998</td>\n",
       "      <td>-12.202797</td>\n",
       "      <td>0.357330</td>\n",
       "      <td>-2.664678</td>\n",
       "      <td>0.129632</td>\n",
       "      <td>-0.518654</td>\n",
       "      <td>-0.660244</td>\n",
       "      <td>0.053999</td>\n",
       "      <td>-0.402659</td>\n",
       "      <td>0.600631</td>\n",
       "      <td>-0.142732</td>\n",
       "      <td>1.218818</td>\n",
       "      <td>0.477372</td>\n",
       "      <td>-0.553137</td>\n",
       "      <td>0.146678</td>\n",
       "      <td>0.300462</td>\n",
       "      <td>0.316426</td>\n",
       "      <td>-0.650139</td>\n",
       "      <td>-1.395237</td>\n",
       "      <td>-0.994617</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>-0.861662</td>\n",
       "      <td>-0.113301</td>\n",
       "      <td>0.545113</td>\n",
       "      <td>-0.169263</td>\n",
       "      <td>-0.667820</td>\n",
       "      <td>-0.386051</td>\n",
       "      <td>0.248706</td>\n",
       "      <td>0.907028</td>\n",
       "      <td>0.172684</td>\n",
       "      <td>-0.157176</td>\n",
       "      <td>0.146365</td>\n",
       "      <td>-0.297332</td>\n",
       "      <td>-0.010240</td>\n",
       "      <td>-0.572084</td>\n",
       "      <td>0.119394</td>\n",
       "      <td>-0.189261</td>\n",
       "      <td>-0.011453</td>\n",
       "      <td>0.246724</td>\n",
       "      <td>0.219450</td>\n",
       "      <td>0.428341</td>\n",
       "      <td>0.390695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>-14.219149</td>\n",
       "      <td>-6.974966</td>\n",
       "      <td>4.092569</td>\n",
       "      <td>-10.268049</td>\n",
       "      <td>-7.130547</td>\n",
       "      <td>0.910125</td>\n",
       "      <td>-2.759280</td>\n",
       "      <td>1.676623</td>\n",
       "      <td>-1.895373</td>\n",
       "      <td>1.155819</td>\n",
       "      <td>1.379139</td>\n",
       "      <td>-0.230294</td>\n",
       "      <td>-1.285763</td>\n",
       "      <td>-1.476808</td>\n",
       "      <td>1.656284</td>\n",
       "      <td>0.186906</td>\n",
       "      <td>0.310823</td>\n",
       "      <td>0.439519</td>\n",
       "      <td>0.061619</td>\n",
       "      <td>-0.920984</td>\n",
       "      <td>0.296011</td>\n",
       "      <td>0.566233</td>\n",
       "      <td>-0.368864</td>\n",
       "      <td>-0.128431</td>\n",
       "      <td>-0.068481</td>\n",
       "      <td>-0.224142</td>\n",
       "      <td>0.179680</td>\n",
       "      <td>-0.320702</td>\n",
       "      <td>0.290704</td>\n",
       "      <td>-0.189246</td>\n",
       "      <td>-0.444375</td>\n",
       "      <td>0.078101</td>\n",
       "      <td>0.115417</td>\n",
       "      <td>0.165679</td>\n",
       "      <td>-0.190984</td>\n",
       "      <td>-0.449885</td>\n",
       "      <td>-0.047568</td>\n",
       "      <td>0.199263</td>\n",
       "      <td>0.258690</td>\n",
       "      <td>-0.128616</td>\n",
       "      <td>-0.042459</td>\n",
       "      <td>-0.317616</td>\n",
       "      <td>-0.092272</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>-0.063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3351</td>\n",
       "      <td>0.552702</td>\n",
       "      <td>16.452711</td>\n",
       "      <td>0.200888</td>\n",
       "      <td>9.764205</td>\n",
       "      <td>-10.341630</td>\n",
       "      <td>-4.134721</td>\n",
       "      <td>1.136563</td>\n",
       "      <td>0.721318</td>\n",
       "      <td>-1.382320</td>\n",
       "      <td>-1.017498</td>\n",
       "      <td>0.900492</td>\n",
       "      <td>-0.738193</td>\n",
       "      <td>0.557065</td>\n",
       "      <td>0.835136</td>\n",
       "      <td>-0.345809</td>\n",
       "      <td>-0.541694</td>\n",
       "      <td>0.097207</td>\n",
       "      <td>0.850524</td>\n",
       "      <td>0.717571</td>\n",
       "      <td>0.664224</td>\n",
       "      <td>0.485868</td>\n",
       "      <td>0.492898</td>\n",
       "      <td>-0.655621</td>\n",
       "      <td>-1.137240</td>\n",
       "      <td>-0.988206</td>\n",
       "      <td>0.344255</td>\n",
       "      <td>-0.367984</td>\n",
       "      <td>0.322410</td>\n",
       "      <td>-0.858273</td>\n",
       "      <td>-0.112213</td>\n",
       "      <td>0.554333</td>\n",
       "      <td>-0.157989</td>\n",
       "      <td>0.426943</td>\n",
       "      <td>0.323402</td>\n",
       "      <td>-0.179111</td>\n",
       "      <td>-0.329133</td>\n",
       "      <td>-0.249454</td>\n",
       "      <td>-0.249699</td>\n",
       "      <td>-0.027556</td>\n",
       "      <td>0.578510</td>\n",
       "      <td>0.179776</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>-0.347475</td>\n",
       "      <td>0.069571</td>\n",
       "      <td>0.076207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3352</td>\n",
       "      <td>-9.193261</td>\n",
       "      <td>1.516230</td>\n",
       "      <td>13.556272</td>\n",
       "      <td>9.754312</td>\n",
       "      <td>-2.245289</td>\n",
       "      <td>-1.547189</td>\n",
       "      <td>1.431038</td>\n",
       "      <td>-1.824192</td>\n",
       "      <td>-1.683107</td>\n",
       "      <td>1.508861</td>\n",
       "      <td>-0.261283</td>\n",
       "      <td>0.912092</td>\n",
       "      <td>-1.048901</td>\n",
       "      <td>0.129092</td>\n",
       "      <td>-0.224621</td>\n",
       "      <td>-0.201628</td>\n",
       "      <td>-0.797789</td>\n",
       "      <td>0.618327</td>\n",
       "      <td>1.719758</td>\n",
       "      <td>1.389927</td>\n",
       "      <td>-0.084604</td>\n",
       "      <td>-0.321313</td>\n",
       "      <td>0.942550</td>\n",
       "      <td>0.510260</td>\n",
       "      <td>-0.626927</td>\n",
       "      <td>-0.090412</td>\n",
       "      <td>-0.782680</td>\n",
       "      <td>0.023509</td>\n",
       "      <td>0.693986</td>\n",
       "      <td>0.383434</td>\n",
       "      <td>0.467984</td>\n",
       "      <td>0.247367</td>\n",
       "      <td>-0.362615</td>\n",
       "      <td>0.148680</td>\n",
       "      <td>0.450915</td>\n",
       "      <td>0.532167</td>\n",
       "      <td>0.193929</td>\n",
       "      <td>0.364556</td>\n",
       "      <td>0.152976</td>\n",
       "      <td>-0.733420</td>\n",
       "      <td>-0.198873</td>\n",
       "      <td>0.150332</td>\n",
       "      <td>0.631933</td>\n",
       "      <td>-0.337254</td>\n",
       "      <td>-0.633653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3353</td>\n",
       "      <td>-14.002240</td>\n",
       "      <td>11.481141</td>\n",
       "      <td>10.546388</td>\n",
       "      <td>-5.651545</td>\n",
       "      <td>-2.751973</td>\n",
       "      <td>-1.785202</td>\n",
       "      <td>-1.588163</td>\n",
       "      <td>-0.468043</td>\n",
       "      <td>-0.513397</td>\n",
       "      <td>-0.286633</td>\n",
       "      <td>-0.127733</td>\n",
       "      <td>0.417873</td>\n",
       "      <td>0.319219</td>\n",
       "      <td>-1.601676</td>\n",
       "      <td>-0.355852</td>\n",
       "      <td>0.949776</td>\n",
       "      <td>1.321055</td>\n",
       "      <td>-0.466218</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.215164</td>\n",
       "      <td>-0.124897</td>\n",
       "      <td>-0.929571</td>\n",
       "      <td>1.170636</td>\n",
       "      <td>0.056090</td>\n",
       "      <td>-0.360790</td>\n",
       "      <td>0.269138</td>\n",
       "      <td>0.275971</td>\n",
       "      <td>0.366157</td>\n",
       "      <td>-1.051488</td>\n",
       "      <td>1.146172</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.211027</td>\n",
       "      <td>-0.204595</td>\n",
       "      <td>-0.298356</td>\n",
       "      <td>0.128604</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.257919</td>\n",
       "      <td>-0.298293</td>\n",
       "      <td>0.097741</td>\n",
       "      <td>0.595202</td>\n",
       "      <td>0.044233</td>\n",
       "      <td>-0.204897</td>\n",
       "      <td>0.153748</td>\n",
       "      <td>-0.073673</td>\n",
       "      <td>0.057116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3354</td>\n",
       "      <td>-8.593283</td>\n",
       "      <td>17.335740</td>\n",
       "      <td>-10.253766</td>\n",
       "      <td>-3.075604</td>\n",
       "      <td>3.936105</td>\n",
       "      <td>-0.428898</td>\n",
       "      <td>-0.303729</td>\n",
       "      <td>1.079620</td>\n",
       "      <td>-1.451576</td>\n",
       "      <td>0.401471</td>\n",
       "      <td>2.079772</td>\n",
       "      <td>-0.448212</td>\n",
       "      <td>0.331674</td>\n",
       "      <td>-0.368228</td>\n",
       "      <td>-0.230561</td>\n",
       "      <td>-0.612628</td>\n",
       "      <td>0.269748</td>\n",
       "      <td>0.421770</td>\n",
       "      <td>1.235473</td>\n",
       "      <td>0.531933</td>\n",
       "      <td>-0.595122</td>\n",
       "      <td>0.423270</td>\n",
       "      <td>0.252607</td>\n",
       "      <td>-0.956349</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>-0.073424</td>\n",
       "      <td>0.096601</td>\n",
       "      <td>-0.338526</td>\n",
       "      <td>0.637254</td>\n",
       "      <td>0.379037</td>\n",
       "      <td>0.194826</td>\n",
       "      <td>-0.340981</td>\n",
       "      <td>0.529198</td>\n",
       "      <td>0.383240</td>\n",
       "      <td>0.041427</td>\n",
       "      <td>0.063592</td>\n",
       "      <td>0.089547</td>\n",
       "      <td>0.006685</td>\n",
       "      <td>-0.084358</td>\n",
       "      <td>-0.078102</td>\n",
       "      <td>0.310691</td>\n",
       "      <td>0.102652</td>\n",
       "      <td>-0.137785</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>0.085886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3355 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4         5   \\\n",
       "0     -1.544289  -0.824992   2.843841  -2.544883   1.313584 -4.510989   \n",
       "1     -9.959137   2.312521  -5.690243  16.131003  -4.432750 -2.355228   \n",
       "2      2.638594  -1.888735   6.522407 -14.471979  -7.173325 -2.281573   \n",
       "3     28.545711  14.048909  -5.890521   8.691848  -2.105240 -2.068995   \n",
       "4     -2.263481  -8.139869  11.287388   4.394998 -12.202797  0.357330   \n",
       "...         ...        ...        ...        ...        ...       ...   \n",
       "3350 -14.219149  -6.974966   4.092569 -10.268049  -7.130547  0.910125   \n",
       "3351   0.552702  16.452711   0.200888   9.764205 -10.341630 -4.134721   \n",
       "3352  -9.193261   1.516230  13.556272   9.754312  -2.245289 -1.547189   \n",
       "3353 -14.002240  11.481141  10.546388  -5.651545  -2.751973 -1.785202   \n",
       "3354  -8.593283  17.335740 -10.253766  -3.075604   3.936105 -0.428898   \n",
       "\n",
       "            6         7         8         9         10        11        12  \\\n",
       "0     1.497924 -1.848113  2.373872 -0.227971 -1.036275 -0.539821 -0.364789   \n",
       "1    -0.752267 -2.927850 -0.955590  0.079541 -0.124049  0.271745 -0.429909   \n",
       "2     0.788575 -1.923893  1.651099 -0.561468 -0.534815  0.374968 -1.352893   \n",
       "3     1.128292 -0.324627 -0.761757 -0.789634  1.633669 -0.576225  1.355751   \n",
       "4    -2.664678  0.129632 -0.518654 -0.660244  0.053999 -0.402659  0.600631   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350 -2.759280  1.676623 -1.895373  1.155819  1.379139 -0.230294 -1.285763   \n",
       "3351  1.136563  0.721318 -1.382320 -1.017498  0.900492 -0.738193  0.557065   \n",
       "3352  1.431038 -1.824192 -1.683107  1.508861 -0.261283  0.912092 -1.048901   \n",
       "3353 -1.588163 -0.468043 -0.513397 -0.286633 -0.127733  0.417873  0.319219   \n",
       "3354 -0.303729  1.079620 -1.451576  0.401471  2.079772 -0.448212  0.331674   \n",
       "\n",
       "            13        14        15        16        17        18        19  \\\n",
       "0    -0.873245  1.028270  0.284276  0.087572  0.058755  0.663960 -1.168575   \n",
       "1    -0.377660  0.436714  0.157337 -0.939837  0.660518  0.523079 -0.391293   \n",
       "2     0.309197 -0.471445  0.084420 -0.212422 -0.024082 -0.304529  0.294787   \n",
       "3    -0.549355  1.015349  2.146519 -0.432140 -0.589044 -0.127133  0.449501   \n",
       "4    -0.142732  1.218818  0.477372 -0.553137  0.146678  0.300462  0.316426   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350 -1.476808  1.656284  0.186906  0.310823  0.439519  0.061619 -0.920984   \n",
       "3351  0.835136 -0.345809 -0.541694  0.097207  0.850524  0.717571  0.664224   \n",
       "3352  0.129092 -0.224621 -0.201628 -0.797789  0.618327  1.719758  1.389927   \n",
       "3353 -1.601676 -0.355852  0.949776  1.321055 -0.466218  0.004641  0.215164   \n",
       "3354 -0.368228 -0.230561 -0.612628  0.269748  0.421770  1.235473  0.531933   \n",
       "\n",
       "            20        21        22        23        24        25        26  \\\n",
       "0    -0.508609  0.590425 -0.746908 -0.419889  0.270636  0.157029 -0.098002   \n",
       "1     0.715742 -0.990164  0.508792 -0.129086  0.261061 -0.515424 -0.066966   \n",
       "2     1.086411 -0.627664  0.396498  0.138865 -0.196387 -0.535898  0.735128   \n",
       "3     0.197901 -0.624637 -0.059979  0.319716  0.766709 -0.512455  0.044984   \n",
       "4    -0.650139 -1.395237 -0.994617  0.009620 -0.861662 -0.113301  0.545113   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350  0.296011  0.566233 -0.368864 -0.128431 -0.068481 -0.224142  0.179680   \n",
       "3351  0.485868  0.492898 -0.655621 -1.137240 -0.988206  0.344255 -0.367984   \n",
       "3352 -0.084604 -0.321313  0.942550  0.510260 -0.626927 -0.090412 -0.782680   \n",
       "3353 -0.124897 -0.929571  1.170636  0.056090 -0.360790  0.269138  0.275971   \n",
       "3354 -0.595122  0.423270  0.252607 -0.956349  0.562786 -0.073424  0.096601   \n",
       "\n",
       "            27        28        29        30        31        32        33  \\\n",
       "0     0.130397  0.328758  0.172485  0.265257  0.549017 -0.145111 -0.081533   \n",
       "1    -0.263788 -0.049874 -0.261616  0.103626 -0.282623 -0.308384 -0.085651   \n",
       "2     0.303894 -0.492485 -0.880517  0.149027 -0.199209  0.132673  0.216160   \n",
       "3     0.236501 -0.246336  0.225709 -0.063760  0.491743  0.171583 -0.360778   \n",
       "4    -0.169263 -0.667820 -0.386051  0.248706  0.907028  0.172684 -0.157176   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350 -0.320702  0.290704 -0.189246 -0.444375  0.078101  0.115417  0.165679   \n",
       "3351  0.322410 -0.858273 -0.112213  0.554333 -0.157989  0.426943  0.323402   \n",
       "3352  0.023509  0.693986  0.383434  0.467984  0.247367 -0.362615  0.148680   \n",
       "3353  0.366157 -1.051488  1.146172  0.017928  0.211027 -0.204595 -0.298356   \n",
       "3354 -0.338526  0.637254  0.379037  0.194826 -0.340981  0.529198  0.383240   \n",
       "\n",
       "            34        35        36        37        38        39        40  \\\n",
       "0     0.217230 -0.029116 -0.072583 -0.152087 -0.228441 -0.159620 -0.102335   \n",
       "1    -0.398509  0.038522  0.362366 -0.057959 -0.335482 -0.068959 -0.203547   \n",
       "2    -0.168315 -0.335381 -0.156473  0.382928  0.102843 -0.201060 -0.040405   \n",
       "3     0.471259 -0.039643 -0.038446  0.086507  0.462486  0.176038  0.263410   \n",
       "4     0.146365 -0.297332 -0.010240 -0.572084  0.119394 -0.189261 -0.011453   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350 -0.190984 -0.449885 -0.047568  0.199263  0.258690 -0.128616 -0.042459   \n",
       "3351 -0.179111 -0.329133 -0.249454 -0.249699 -0.027556  0.578510  0.179776   \n",
       "3352  0.450915  0.532167  0.193929  0.364556  0.152976 -0.733420 -0.198873   \n",
       "3353  0.128604  0.003427 -0.257919 -0.298293  0.097741  0.595202  0.044233   \n",
       "3354  0.041427  0.063592  0.089547  0.006685 -0.084358 -0.078102  0.310691   \n",
       "\n",
       "            41        42        43        44  \n",
       "0     0.130208 -0.020124 -0.176160  0.182580  \n",
       "1     0.167375 -0.059329 -0.043762  0.087622  \n",
       "2     0.226012 -0.006598  0.147990 -0.390312  \n",
       "3    -0.091008  0.009368  0.395739 -0.456148  \n",
       "4     0.246724  0.219450  0.428341  0.390695  \n",
       "...        ...       ...       ...       ...  \n",
       "3350 -0.317616 -0.092272  0.016799 -0.063783  \n",
       "3351  0.015193 -0.347475  0.069571  0.076207  \n",
       "3352  0.150332  0.631933 -0.337254 -0.633653  \n",
       "3353 -0.204897  0.153748 -0.073673  0.057116  \n",
       "3354  0.102652 -0.137785 -0.001971  0.085886  \n",
       "\n",
       "[3355 rows x 45 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cName \t PearSon Coree \t\t pvalue \n",
      "\n",
      "0 \t 19.476964092350325 \t 4.880761112687273e-30\n",
      "2 \t -7.23061337803006 \t 2.7642176841138013e-05\n",
      "3 \t -8.093504631002178 \t 2.680400243445476e-06\n",
      "6 \t 18.344086737234452 \t 8.903178851827968e-27\n",
      "7 \t -34.57372734458168 \t 8.127118222939264e-95\n",
      "9 \t 31.093072670774436 \t 4.1256359312919345e-76\n",
      "10 \t -11.316131364364846 \t 4.9228326474586266e-11\n",
      "11 \t -29.876905090696603 \t 3.8452100198525876e-70\n",
      "12 \t 11.941213753789302 \t 3.951765431751376e-12\n",
      "13 \t -16.01185789527532 \t 1.0462584386715168e-20\n",
      "14 \t 3.753159593419725 \t 0.029714564513471254\n",
      "15 \t 14.896204879766747 \t 4.192208847501762e-18\n",
      "16 \t -33.09368859024604 \t 1.4586659568641882e-86\n",
      "17 \t 6.316464929693377 \t 0.000251293339807451\n",
      "19 \t 3.9411050761613495 \t 0.02244113003210641\n",
      "20 \t 6.758007268382246 \t 8.950261964474766e-05\n",
      "21 \t 6.2876699816973876 \t 0.0002682082203906298\n",
      "22 \t 6.440725822601645 \t 0.00018913248021543312\n",
      "24 \t -3.980860703617737 \t 0.021118272734975706\n",
      "25 \t 4.482145780419756 \t 0.009417832369759061\n",
      "32 \t -8.973959252684681 \t 1.9243630728448252e-07\n",
      "\n",
      " No of PCAs Highly Correlate with Target Veriable: ==>: 21 Outof_Available PCAs 45\n"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "print (\"cName\",\"\\t\", \"PearSon Coree\",\"\\t\\t\", \"pvalue\",\"\\n\")\n",
    "for col in X_train_pca_df.columns:\n",
    "    corre, pvalue = stats.pearsonr(X_train_pca_df[col], y_train)\n",
    "    \n",
    "    if (pvalue < 0.03):\n",
    "        print (col,\"\\t\", corre*100,\"\\t\", pvalue)\n",
    "        columns.append(col)\n",
    "print(\"\\n No of PCAs Highly Correlate with Target Veriable: ==>:\", len(columns), \"Outof_Available PCAs\",X_train_pca_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df_final = X_train_pca_df[columns]\n",
    "X_test_pca_df_final = X_test_pca_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mMS = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_test_pca_df_final.columns:\n",
    "    X_train_pca_df_final[col] = mMS.fit_transform(np.array(X_train_pca_df_final[col]).reshape(-1,1))\n",
    "    X_test_pca_df_final[col] = mMS.transform(np.array(X_test_pca_df_final[col]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Execute(xtrain, xtest, ytrain, ytest, model):\n",
    "    obj = model\n",
    "    obj.fit(xtrain, ytrain)\n",
    "    y_predict = obj.predict(xtest)\n",
    "    y_predict_train = obj.predict(xtrain)\n",
    "    \n",
    "    test_r2_score = r2_score(ytest, y_predict)\n",
    "    train_r2_score = r2_score(ytrain, y_predict_train)\n",
    "    print(str(obj).split(\"(\")[0])\n",
    "    print(\"Train Accuracy(R2 Score): ===========>\", train_r2_score)\n",
    "    print(\"Test Accuracuy(R2 Score): ===========>\", test_r2_score)\n",
    "    print(\"MeanSquareError: ====================>\", mean_squared_error(ytest, y_predict))\n",
    "    print(\"RootMeanSquareError: ================>\", np.sqrt(mean_squared_error(ytest, y_predict)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'lr': LinearRegression(),\n",
    "    'dt': DecisionTreeRegressor(),\n",
    "    'rf': RandomForestRegressor(),\n",
    "    'agb': AdaBoostRegressor(),\n",
    "    'gbr': GradientBoostingRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Train Accuracy(R2 Score): ===========> 0.604518511440505\n",
      "Test Accuracuy(R2 Score): ===========> 0.6337437388455567\n",
      "MeanSquareError: ====================> 0.005347807288918421\n",
      "RootMeanSquareError: ================> 0.07312870359112365 \n",
      "\n",
      "DecisionTreeRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.9775554769646672\n",
      "Test Accuracuy(R2 Score): ===========> 0.3255619071883816\n",
      "MeanSquareError: ====================> 0.009847654036803773\n",
      "RootMeanSquareError: ================> 0.0992353467107551 \n",
      "\n",
      "RandomForestRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.9226489846390744\n",
      "Test Accuracuy(R2 Score): ===========> 0.6058184152382553\n",
      "MeanSquareError: ====================> 0.005755552534451733\n",
      "RootMeanSquareError: ================> 0.07586535793398547 \n",
      "\n",
      "AdaBoostRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.23599047916621552\n",
      "Test Accuracuy(R2 Score): ===========> 0.20378845689679248\n",
      "MeanSquareError: ====================> 0.011625701306257816\n",
      "RootMeanSquareError: ================> 0.10782254544508683 \n",
      "\n",
      "GradientBoostingRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.6984425112472966\n",
      "Test Accuracuy(R2 Score): ===========> 0.6192918631514881\n",
      "MeanSquareError: ====================> 0.0055588230567627074\n",
      "RootMeanSquareError: ================> 0.07455751509246206 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mName, Model in models.items():\n",
    "    model_Execute(X_train_pca_df_final, X_test_pca_df_final, y_train, y_test, Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linRig = LinearRegression()\n",
    "linRig.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy(R2 Score): ===========> 0.6060800238253873 \n",
      "\n",
      "Test Accuracuy(R2 Score): ===========> 0.6365124683216239 \n",
      "\n",
      "MeanSquareError: ====================> 0.005307380316758313 \n",
      "\n",
      "RootMeanSquareError: ================> 0.07285176948268526\n"
     ]
    }
   ],
   "source": [
    "y_predict_linRig = linRig.predict(X_test_pca_df_final)\n",
    "\n",
    "print(\"Train Accuracy(R2 Score): ===========>\", linRig.score(X_train_pca_df_final, y_train), \"\\n\")\n",
    "print(\"Test Accuracuy(R2 Score): ===========>\", linRig.score(X_test_pca_df_final, y_test), \"\\n\")\n",
    "\n",
    "print(\"MeanSquareError: ====================>\", mean_squared_error(y_test, y_predict_linRig), \"\\n\")\n",
    "print(\"RootMeanSquareError: ================>\", np.sqrt(mean_squared_error(y_test, y_predict_linRig)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "adbR = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "adbR_params = {\n",
    "    'n_estimators': np.arange(5, 200, 5),\n",
    "    'learning_rate': np.linspace(0.0001, 1, 15),\n",
    "    'loss': ['linear', 'square', 'exponential'],\n",
    "    \"base_estimator__criterion\" : [\"friedman_mse\", \"mse\"],\n",
    "    \"base_estimator__min_samples_split\": np.arange(1, 20, 1),\n",
    "    \"base_estimator__min_samples_leaf\": np.arange(1, 20, 1),\n",
    "    \"base_estimator__max_depth\" : np.arange(1, 20, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsCV = RandomizedSearchCV(estimator=adbR, param_distributions=adbR_params, scoring='r2', n_jobs=-1, n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                                    criterion='mse',\n",
       "                                                                                    max_depth=None,\n",
       "                                                                                    max_features=None,\n",
       "                                                                                    max_leaf_nodes=None,\n",
       "                                                                                    min_impurity_decrease=0.0,\n",
       "                                                                                    min_impurity_split=None,\n",
       "                                                                                    min_samples_leaf=1,\n",
       "                                                                                    min_samples_split=2,\n",
       "                                                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                                                    presort='deprecated',\n",
       "                                                                                    random_state=None,\n",
       "                                                                                    sp...\n",
       "       8.57157143e-01, 9.28578571e-01, 1.00000000e+00]),\n",
       "                                        'loss': ['linear', 'square',\n",
       "                                                 'exponential'],\n",
       "                                        'n_estimators': array([  5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,\n",
       "        70,  75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130,\n",
       "       135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsCV.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rsCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                       criterion='mse',\n",
       "                                                       max_depth=11,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=6,\n",
       "                                                       min_samples_split=7,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       presort='deprecated',\n",
       "                                                       random_state=None,\n",
       "                                                       splitter='best'),\n",
       "                  learning_rate=0.07152142857142857, loss='square',\n",
       "                  n_estimators=110, random_state=2020)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.8350195249592972\n",
      "Test Accuracuy(R2 Score): ===========> 0.6253974406515722\n",
      "MeanSquareError: ====================> 0.005469673858998583\n",
      "RootMeanSquareError: ================> 0.07395724345186604 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_Execute(X_train_pca_df_final, X_test_pca_df_final, y_train, y_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble_Boosting ===> [GradientBoostingRegressor Model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbR = GradientBoostingRegressor()\n",
    "gbR.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy(R2 Score): ===========> 0.6975576486786084 \n",
      "\n",
      "Test Accuracuy(R2 Score): ===========> 0.6201671823812012 \n",
      "\n",
      "MeanSquareError: ====================> 0.005546042282607379 \n",
      "\n",
      "RootMeanSquareError: ================> 0.07447175493170131\n"
     ]
    }
   ],
   "source": [
    "y_predict_gbR = gbR.predict(X_test_pca_df_final)\n",
    "\n",
    "\n",
    "# initially overfitted after tunning R2 = 0.52\n",
    "\n",
    "print(\"Train Accuracy(R2 Score): ===========>\", gbR.score(X_train_pca_df_final, y_train), \"\\n\")\n",
    "print(\"Test Accuracuy(R2 Score): ===========>\", gbR.score(X_test_pca_df_final, y_test), \"\\n\")\n",
    "\n",
    "print(\"MeanSquareError: ====================>\", mean_squared_error(y_test, y_predict_gbR), \"\\n\")\n",
    "print(\"RootMeanSquareError: ================>\", np.sqrt(mean_squared_error(y_test, y_predict_gbR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Hyper ParameterTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbR = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbCV = cross_val_score(gbR, cv=5, X=X_train_pca_df_final, y=y_train, scoring=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5837844259827183"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbCV.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbR.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre = gbR.predict(X_train_pca_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre = gbR.predict(X_test_pca_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975576486786087"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, train_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.620308424106651"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbR_hyp = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_params = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'loss': ['ls', 'lad', 'huber'],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': np.arange(1, 8),\n",
    "    'n_estimators': [5, 10, 15, 20],\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "score = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_rsCV = RandomizedSearchCV(gbR_hyp, param_distributions=gbr_params, scoring=score, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100...\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                                        'loss': ['ls', 'lad', 'huber'],\n",
       "                                        'max_depth': [2, 3, 4, 5],\n",
       "                                        'min_samples_leaf': array([1, 2, 3, 4, 5, 6, 7]),\n",
       "                                        'n_estimators': [5, 10, 15, 20],\n",
       "                                        'tol': [0.0001, 0.001, 0.01, 0.1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=make_scorer(r2_score),\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_rsCV.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_hyp_best = gbr_rsCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_hyp_best.bes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='huber',\n",
       "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=5, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=42, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_hyp_best.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrcv_scores = cross_val_score(gbr_hyp_best, X=X_train_pca_df_final, y=y_train, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5221947029942126"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrcv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5429821082581806"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_hyp_best.score(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5755589693025854"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_hyp_best.score(X_test_pca_df_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5564674384727663"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svrR = SVR(kernel='poly', degree=3, C=2, gamma=0.5)\n",
    "svrR.fit(X_train_pca_df_final, y_train)\n",
    "svrR.score(X_test_pca_df_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy(R2 Score): ===========> 0.6114062164632249 \n",
      "\n",
      "Test Accuracuy(R2 Score): ===========> 0.5564674384727663 \n",
      "\n",
      "MeanSquareError: ====================> 0.006476139569414218 \n",
      "\n",
      "RootMeanSquareError: ================> 0.08047446532543237\n"
     ]
    }
   ],
   "source": [
    "y_predict_svrR = svrR.predict(X_test_pca_df_final)\n",
    "\n",
    "\n",
    "# initially overfitted after tunning R2 = 0.52\n",
    "\n",
    "print(\"Train Accuracy(R2 Score): ===========>\", svrR.score(X_train_pca_df_final, y_train), \"\\n\")\n",
    "print(\"Test Accuracuy(R2 Score): ===========>\", svrR.score(X_test_pca_df_final, y_test), \"\\n\")\n",
    "\n",
    "print(\"MeanSquareError: ====================>\", mean_squared_error(y_test, y_predict_svrR), \"\\n\")\n",
    "print(\"RootMeanSquareError: ================>\", np.sqrt(mean_squared_error(y_test, y_predict_svrR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "           'LR': LinearRegression(), \n",
    "          'DTR': DecisionTreeRegressor(), \n",
    "          'RFS': RandomForestRegressor(), \n",
    "          'ADB': AdaBoostRegressor()\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LR Model TrainAcc: ====>0.6112955965847053 TestAccuracy          : ====>0.6404050652958228\n",
      "LR Model R2 Score: ====>0.6404050652958228 Model MeanSquare Error: ====>0.005250543449571858\n",
      "\n",
      "\n",
      "\n",
      "DTR Model TrainAcc: ====>0.977555457783147 TestAccuracy          : ====>0.2622579467356776\n",
      "DTR Model R2 Score: ====>0.2622579467356776 Model MeanSquare Error: ====>0.01077197238172244\n",
      "\n",
      "\n",
      "\n",
      "RFS Model TrainAcc: ====>0.9222606060810147 TestAccuracy          : ====>0.613283547745761\n",
      "RFS Model R2 Score: ====>0.613283547745761 Model MeanSquare Error: ====>0.005646552104232339\n",
      "\n",
      "\n",
      "\n",
      "ADB Model TrainAcc: ====>0.2648100213796104 TestAccuracy          : ====>0.23480173084074052\n",
      "ADB Model R2 Score: ====>0.23480173084074052 Model MeanSquare Error: ====>0.011172868057952657\n"
     ]
    }
   ],
   "source": [
    "for mName, model in models.items():\n",
    "    obj = models[mName]\n",
    "    obj.fit(X_train_pca_df, y_train)\n",
    "    y_predict = obj.predict(X_test_pca_df)\n",
    "    \n",
    "    train_acc = obj.score(X_train_pca_df, y_train)\n",
    "    test_acc =  obj.score(X_test_pca_df, y_test)\n",
    "    \n",
    "    R2Square = r2_score(y_test, y_predict)\n",
    "    MSquareE = mean_squared_error(y_test, y_predict)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(\"{} Model TrainAcc: ====>{} TestAccuracy          : ====>{}\".format(mName, train_acc, test_acc))\n",
    "    print(\"{} Model R2 Score: ====>{} Model MeanSquare Error: ====>{}\".format(mName, R2Square, MSquareE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
